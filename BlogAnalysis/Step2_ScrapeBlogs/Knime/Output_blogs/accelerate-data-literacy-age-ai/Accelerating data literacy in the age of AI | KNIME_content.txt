Industry experts’ perspective at KNIME DataHop Europe
The emergence of GenAI has brought about a profound revolution in the realm of data science, fundamentally reshaping the roles, procedures, and prospects for both data scientists and organizations. This transformative shift has not only streamlined the pace of innovation but has also democratized the accessibility of data science tools, enabling individuals from varied backgrounds to engage in the creation of advanced analytical solutions. Consequently, the landscape of data science has evolved into one that is more dynamic and inclusive, fostering opportunities for collaboration and discovery.
At the recent KNIME DataHop Europe in Munich, four industry experts, Ulrich Wagner, CEO, Wimex Group, Philipp Kowalski, Digital Enablement Agent, Siemens, Michael Wolff, Partner, Thaltegos, and Maxim Rube, Service Owner, Siemens Healthineers joined a panel to discuss data literacy and AI, hosted by Rosaria Silipo, VP of Data Science Evangelism at KNIME.
Read this write-up of the discussion where they delved into the importance of data literacy, debated strategies for implementing successful data literacy programs within the organization, and shared views on how AI can foster customized learning and upskilling.
*** 
Rosaria: How do you define a “data literate” individual within your organizations?
Philipp: During our finance training sessions, we introduce KNIME Analytics Platform to colleagues who work in finance and usually have experience with Excel. Within the first hour, attendees often start experimenting with KNIME nodes to build basic ETL workflows, applying column and row filters. This initial application of data science principles to their specific use cases marks, in my opinion, the first step towards data literacy. 
Maxim: Data literacy is about building a strong foundation to work with data. Concretely, this means having a solid grip on data types, mastering various data handling techniques, and understanding key visualization methods. While different departments like finance or marketing may have specific needs, the fundamentals never change. The ability to integrate visualization tools into data storytelling is an essential skill across all departments within a company. 
Ulrich: To me data literacy means moving beyond basic Excel skills. It's about solving problems efficiently, not just compiling data in spreadsheets. Data literacy is achieved when individuals can harness automation, consolidate data, and make it more accessible and comprehensible. The next step is realizing the potential of predictive models for better decision-making.
Michael: Data literacy starts with having a mindset inclined towards problem-solving with data. It's about being resourceful and adaptable with the tools and platforms available. Data literacy is essential for individuals to approach problems creatively, seeing data not just as numbers but as a means to extract valuable insights. This mindset shift is crucial for moving beyond traditional tools like Excel. 
Rosaria: It’s interesting that Ulrich understands data literacy as a top-down process, while Philipp as a bottom-up progression. What are the benefits to each of these approaches?
Ulrich: In our case, I realized that sustainable change wouldn't happen overnight. I decided to kickstart the process by appointing a manager solely dedicated to this. Strategically driving initiatives around AI or data literacy is crucial for success. You can hire specialists, but in smaller or medium-sized enterprises, you need leadership buy-in. Without it, implementation may not meet expectations. In that perspective, the advantage of a top-down approach is that it ensures action.
Philipp: In our organization, we do drive data literacy initiatives from the bottom-up but we also have senior executives encourage experimentation, much like the Google Friday concept where employees are encouraged to use 10%-20% of their time to explore new things, without worrying about an immediate return on investment.
Maxim: We're taking a hybrid approach. We have a dedicated department driving data literacy, but also professionals like Philipp who are championing the cause by inspiring others. It's a balanced approach where top-down provides frameworks and platforms, while bottom-up initiatives, like those led by Philipp, are encouraged. There's no one-size-fits-all approach, but rather a hybrid method that works perfectly for us.
Michael: I believe starting from the bottom up is crucial as it establishes a strong foundation. Then, with buy-in from senior leadership, momentum and acceleration in data literacy efforts follow, ensuring high motivation from the bottom up. This approach also provides reassurance and support from top-level executives, maximizing the impact within the organization. 
Rosaria: Can you share practical tips for promoting data literacy in the organization? Is the organization of traditional workshops helpful, or are other solutions, such as organizing challenges or hackathons, more effective? 
Michael: Accessibility of resources and daily commitment are key in data literacy. For example, integrating an AI assistant like K-AI into workflows is very easy and can enhance skills at all levels. At the same time, it's important to have platforms where the community can connect and exchange ideas, whether virtually or in person. Events like DataHops foster debate and knowledge-sharing; whereas initiatives like the KNIME Game of Nodes tournament are particularly engaging and foster the acquisition of new practical skills.
I believe that the perfect mix to advance data literacy effectively is to combine technology and community engagement.
Maxim: It varies because some prefer self-paced online courses due to their busy schedules. Others are inspired to learn more, even dedicating week-ends to do it. Different job roles also influence learning preferences. In finance, time constraints make it challenging to pursue data literacy during the workday. On the other hand, marketing teams might benefit more from workshops, given their frequent interaction with data. 
Philipp: I always assumed that people were more interested in receiving a raise rather than visibility, but I was wrong, at least in our environment. During our monthly meeting with the Finance Leadership Team and the CFO, we've introduced a slot for someone to present, providing an opportunity for recognition and exposure. Additionally, we organize activities like Shark Tank-style events, with winners getting a chance to present to senior management, further boosting their visibility. 
Ulrich: I feel there is a need for real-life examples, particularly simpler ones. Providing these baseline examples would generate more interest, especially when individuals can relate to their own experiences. Showcasing how easy reporting and formatting can be with tools like KNIME Analytics Platform compared to Excel can significantly boost acceptance among users who are familiar with Excel's limitations.
Rosaria: To really boost data literacy we need to be able to accommodate different learning preferences. Do you think that AI can help?
Maxim: Certainly, AI can help improve and tailor the learning experience to the needs of each learner. If you think of the interaction with AI and LLMs, it’s usually a chat with several back and forth questions. The learner can ask what he/she needs, gets responses or feedback by the model to phrase the request more precisely, and can further interact with the model to fine-tune the output he/she gets. In that sense, I do think that there’s a lot of potential for exploring the application of GenAI for educational purposes - be it in courses, educational material or other resources.
Philipp: I'm a bit hesitant because my initial experience wasn't great. I asked for instructions on how to implement complex conditions in the Column Expressions node that uses JavaScript syntax. The JavaScript code that ChatGPT gave me resulted in a blank table and it took me hours to troubleshoot the mistake. So, will we only have Python Script nodes filled by AI-generated code in the future? I don’t think so. However, I see potential in using GenAI for fine-tuning and customization, that is using AI as an improvement tool rather than a tool for creating solutions from scratch.  
Ulrich: AI can alleviate the burden of mastering a programming language by providing assistance, reducing frustration, and building confidence. It's not just a black box; it's also a tool for enhancing quality and speed, integral to the learning curve. In that sense, AI can act as a mentor facilitating access to data literacy and offering a chance to learn by doing.
Michael: While there are risks involved in relying solely on AI for work, I do agree that using it as a mentor can be beneficial to speed up processes and increase productivity. You will still need to know what you want to achieve and what complexities of the data project to address, but AI can be invaluable to handle some technical aspects. 
Rosaria: My last question also touches on AI. Is the popularity of generative AI motivating more people in your organization to upskill themselves?
Philipp: Currently, we're running a program where we teach KNIME. In the first round, we had approximately 17 participants. In the second round, we decided to include some content about AI in the course description and there was a sudden surge in interest, with over 50 people registering within the first 48 hours. 
I did not expect finance people to be so interested in AI, but the message that came across is that AI is not only applicable to finance but it’s a great tool to become data literate and derive meaning from data in everyday business operations. 
Ulrich: AI has been a driver in the tech industry for years, especially in solutions like remote sensing and crop detection. Monetizing AI solutions though can be challenging. While it's easy to talk about AI, making it profitable is another matter. Determining the value of AI and making it financially viable remains a significant challenge.
Michael: There's now much more attention on the type and quality of data, which wasn't the case in the past. Previously, systems supported processes without much consideration for data quality. It's crucial to understand the data we have and its quality, as it heavily influences the type of AI solutions we can develop. Ensuring high-quality data sources is currently a major topic of discussion.
Maxim: While data quality has been a focus, it’s the accessibility of AI tools that has really elevated the conversation and triggered widespread interest in its potential. With ChatGPT accessible to everyone, there's increased interest in exploring its capabilities, sparking excitement and upskilling across departments.
You can catch up on more panel discussions and talks from other previous events in on-demand videos. And the next KNIME event to attend live is the KNIME Spring Summit, April 15-17. You can attend onsite or join the live stream. 
Get your tickets for an onsite or online pass today!